{"id":"meld-eq0","title":"Meld v1: Multi-Model Plan Convergence Tool","description":"# Meld v1 Epic\n\n## Vision\nMeld is a Python CLI tool that orchestrates multi-model plan convergence. Given a task description, it uses Claude as the \"Melder\" to generate an initial plan, then collects parallel feedback from three AI advisors (Claude CLI, Gemini CLI, Codex CLI), synthesizes the feedback, and iterates until convergence or max rounds.\n\n## Why This Matters\n- **Model Diversity**: Different AI models have different strengths, blind spots, and perspectives. Combining their feedback produces more robust plans than any single model.\n- **Convergence as Quality Signal**: When multiple models agree a plan is complete, confidence is higher. Disagreement surfaces risks and edge cases.\n- **Human-in-the-Loop**: The DEFERRED items mechanism ensures humans make final calls on contested decisions.\n\n## Key Design Goals\n1. **Advisor Adapter Layer**: Encapsulate per-CLI quirks (flags, output parsing) so CLI drift doesn't break the core loop\n2. **Session Persistence**: Crash-safe artifacts enable debugging, `--resume`, and meet PRD requirement \"no data loss if interrupted\"\n3. **Structured Feedback**: Lightly structured advisor responses improve synthesis quality and convergence accuracy\n4. **Real-time Visibility**: Textual TUI shows all four models working in parallel with streaming output\n\n## Architecture Summary\n- **Language**: Python 3.10+ (required for Textual/Rich; modern async support)\n- **TUI Framework**: Textual (purpose-built for terminal apps; handles layout, streaming, async natively)\n- **CLI Invocation**: asyncio.create_subprocess_exec (non-blocking parallel execution; stdout streaming)\n- **Output Format**: Markdown + optional JSON (Markdown for humans, JSON for CI/scripting)\n- **Configuration**: CLI flags only (no config files for v1; keeps it simple)\n\n## Implementation Phases\n1. **Foundation**: Project scaffolding, CLI, session manager, provider interface\n2. **Core Logic**: All provider adapters, Melder, Advisor pool, convergence detection\n3. **TUI**: Textual app with 4-panel layout, streaming, status indicators\n4. **Polish**: Output formatter, JSON output, resume, graceful degradation\n\n## Success Criteria\n- All CLIs invoked successfully when available\n- Preflight detects missing/broken CLIs with actionable messages\n- TUI renders without flicker with throttled updates\n- Convergence detection: no false positives; OPEN_ITEMS \u003e 0 always blocks\n- Graceful degradation: works with 2/3 advisors\n- Session artifacts enable crash recovery via --resume\n\n## Dependencies\n### External (user must have installed)\n- `claude` CLI - Anthropic's Claude Code CLI (authenticated)\n- `gemini` CLI - Google's Gemini CLI (authenticated)\n- `codex` CLI - OpenAI's Codex CLI (authenticated)\n- Python 3.10+\n\n### Python Packages\n- `textual\u003e=0.50.0` - TUI framework\n- `rich\u003e=13.0.0` - Terminal formatting (Textual dependency)\n\n## Deferred to v1.1\n- Event-driven architecture (event bus for TUI/logging separation)\n- Context size guardrails (--max-context-chars, PRD summarization)\n- Semantic oscillation detection\n- Advisor specialization hints\n- Cost tracking and token usage estimation","status":"open","priority":1,"issue_type":"epic","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T22:58:31.635092-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T22:58:31.635092-06:00","labels":["epic","python","tui","v1"]}
{"id":"meld-eq0.1","title":"Task 1: Project Setup \u0026 CLI Foundation","description":"# Task 1: Project Setup \u0026 CLI Foundation\n\n## Overview\nEstablish the Python project structure and implement the CLI entry point with all input modes. This is the foundational layer that everything else builds upon.\n\n## Why This Task Exists\nBefore any business logic can be implemented, we need:\n1. A properly configured Python project with modern tooling (pyproject.toml, proper packaging)\n2. A CLI interface that handles all input modes the user might want\n3. Directory structure that matches the architectural vision\n\n## Design Decisions Made\n\n### Project Structure Choice\nUsing flat `meld/` package structure rather than `src/meld/` because:\n- Simpler for a standalone CLI tool\n- Direct import paths (`from meld.cli import ...`)\n- Standard pattern for single-package projects\n\n### CLI Framework: argparse (stdlib)\nChose argparse over click/typer because:\n- Zero additional dependencies\n- Sufficient for our needs (2 subcommands, ~15 flags)\n- Better control over help formatting\n- No magic decorators to understand\n\n### Input Mode Priority (when multiple provided)\n1. Positional arg (highest priority)\n2. --file flag\n3. stdin (auto-detected when piped)\n\nRationale: Explicit arguments should win over implicit (stdin).\n\n## Technical Requirements\n\n### Directory Structure\n```\nmeld/\n├── __init__.py          # Version, package metadata\n├── __main__.py          # Entry point for python -m meld\n├── cli.py               # argparse setup, subcommands\n├── orchestrator.py      # Main loop (stub for now)\n├── melder.py            # Claude integration (stub)\n├── advisors.py          # Advisor pool (stub)\n├── session.py           # Session management (stub)\n├── preflight.py         # Preflight checks (stub)\n├── tui.py               # Textual app (stub)\n├── output.py            # Output formatting (stub)\n├── signals.py           # Signal handling (stub)\n├── prompts.py           # Prompt templates (stub)\n├── providers/           # Provider adapters\n│   ├── __init__.py\n│   ├── base.py          # Abstract base (stub)\n│   ├── claude.py        # Claude adapter (stub)\n│   ├── gemini.py        # Gemini adapter (stub)\n│   └── openai.py        # OpenAI adapter (stub)\n└── models.py            # Data models/types\n```\n\n### pyproject.toml Requirements\n- Build system: hatchling (modern, fast, minimal config)\n- Python: \u003e=3.10\n- Dependencies: textual\u003e=0.50.0, rich\u003e=13.0.0\n- Entry point: `meld = meld.cli:main`\n- Dev dependencies: pytest, pytest-asyncio, ruff\n\n### CLI Interface\n```bash\n# Main command with task\nmeld run \"Build an auth system\"\n\n# Read from file\nmeld run --file task.txt\n\n# Pipe from stdin\necho \"Build auth\" | meld run\n\n# With PRD context\nmeld run \"Build auth\" --prd requirements.md\n\n# Run options\nmeld run \"Task\" --rounds 5 --timeout 600\nmeld run \"Task\" --output plan.md --json-output summary.json\nmeld run \"Task\" --quiet  # No TUI, stdout output\nmeld run \"Task\" --verbose  # Include raw advisor outputs\n\n# Session management\nmeld run --resume 2026-01-16T02-47-17Z-abc123\nmeld run \"Task\" --run-dir ./custom-runs/\n\n# Skip preflight\nmeld run \"Task\" --skip-preflight\n\n# Doctor subcommand\nmeld doctor\n```\n\n## Acceptance Criteria\n- [ ] `pip install -e .` works from project root\n- [ ] `meld --help` shows usage with all flags documented\n- [ ] `meld run \"task\"` accepts positional argument\n- [ ] `meld run --file task.txt` reads from file\n- [ ] `echo \"task\" | meld run` reads from stdin\n- [ ] `meld run --prd doc.md` loads PRD content\n- [ ] `meld doctor` runs (even if stub)\n- [ ] All flags parse correctly (no errors)\n- [ ] Version displayed with `meld --version`\n\n## Notes for Implementation\n- Start with just the CLI parsing, not the actual execution\n- Stubs should print \"Not implemented yet\" and exit cleanly\n- Use type hints throughout (Python 3.10+ syntax)\n- Include docstrings for public functions","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T22:59:44.858502-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T22:59:44.858502-06:00","labels":["cli","foundation","phase-1"],"dependencies":[{"issue_id":"meld-eq0.1","depends_on_id":"meld-eq0","type":"parent-child","created_at":"2026-01-15T22:59:44.864126-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.1.1","title":"1.1: Create pyproject.toml with modern Python packaging","description":"# Subtask 1.1: Create pyproject.toml\n\n## What to Create\nA modern Python project configuration using pyproject.toml with hatchling build system.\n\n## Why hatchling?\n- Modern, fast, PEP 517/518 compliant\n- Minimal configuration needed\n- Good defaults for package discovery\n- Active development and community support\n\n## File Content Requirements\n\n```toml\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"meld\"\nversion = \"0.1.0\"\ndescription = \"Multi-model plan convergence orchestrator\"\nreadme = \"README.md\"\nlicense = \"MIT\"\nrequires-python = \"\u003e=3.10\"\nauthors = [\n    { name = \"Your Name\", email = \"you@example.com\" }\n]\nkeywords = [\"ai\", \"cli\", \"planning\", \"convergence\"]\nclassifiers = [\n    \"Development Status :: 3 - Alpha\",\n    \"Environment :: Console\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Topic :: Software Development :: Quality Assurance\",\n]\ndependencies = [\n    \"textual\u003e=0.50.0\",\n    \"rich\u003e=13.0.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest\u003e=7.0\",\n    \"pytest-asyncio\u003e=0.21\",\n    \"ruff\u003e=0.1.0\",\n]\n\n[project.scripts]\nmeld = \"meld.cli:main\"\n\n[project.urls]\nHomepage = \"https://github.com/yourname/meld\"\nDocumentation = \"https://github.com/yourname/meld#readme\"\nRepository = \"https://github.com/yourname/meld\"\n\n[tool.hatch.build.targets.wheel]\npackages = [\"meld\"]\n\n[tool.ruff]\nline-length = 100\ntarget-version = \"py310\"\n\n[tool.ruff.lint]\nselect = [\"E\", \"F\", \"I\", \"UP\", \"B\"]\n\n[tool.pytest.ini_options]\nasyncio_mode = \"auto\"\ntestpaths = [\"tests\"]\n```\n\n## Acceptance Criteria\n- [ ] File exists at project root\n- [ ] `pip install -e .` succeeds\n- [ ] `pip install -e \".[dev]\"` installs dev dependencies\n- [ ] `meld` command is available after install\n\n## Considerations\n- Version starts at 0.1.0 (pre-release, unstable API)\n- MIT license for maximum flexibility\n- Dev dependencies separate to keep production install slim","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:00:09.253817-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:00:09.253817-06:00","labels":["foundation","packaging"],"dependencies":[{"issue_id":"meld-eq0.1.1","depends_on_id":"meld-eq0.1","type":"parent-child","created_at":"2026-01-15T23:00:09.25725-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.1.2","title":"1.2: Create directory structure with stub modules","description":"# Subtask 1.2: Create Directory Structure\n\n## What to Create\nThe complete directory structure with stub implementations for all modules.\n\n## Directory Layout\n```\nmeld/\n├── __init__.py          # Package init with version\n├── __main__.py          # python -m meld support\n├── cli.py               # CLI entry point (stub)\n├── orchestrator.py      # Main loop\n├── melder.py            # Claude Melder\n├── advisors.py          # Advisor pool\n├── session.py           # Session management\n├── preflight.py         # Preflight checks\n├── tui.py               # Textual TUI\n├── output.py            # Output formatting\n├── signals.py           # Signal handling\n├── prompts.py           # Prompt templates\n├── models.py            # Data classes/types\n└── providers/\n    ├── __init__.py\n    ├── base.py          # Abstract base adapter\n    ├── claude.py        # Claude adapter\n    ├── gemini.py        # Gemini adapter\n    └── openai.py        # OpenAI/Codex adapter\n\ntests/\n├── __init__.py\n├── test_cli.py          # CLI tests (stub)\n└── conftest.py          # pytest fixtures\n```\n\n## Stub Implementation Pattern\nEach module should have a docstring explaining its purpose and any placeholder code:\n\n```python\n\"\"\"\nmeld/orchestrator.py - Main convergence loop.\n\nThis module coordinates the Melder and Advisors through\nthe plan → feedback → synthesis cycle until convergence\nor max rounds reached.\n\"\"\"\n\nasync def run_convergence_loop(task: str, prd: str | None = None) -\u003e str:\n    \"\"\"Run the main convergence loop.\n    \n    Args:\n        task: The task description to plan for\n        prd: Optional PRD content for context\n        \n    Returns:\n        The final converged plan as markdown\n    \"\"\"\n    raise NotImplementedError(\"Orchestrator not yet implemented\")\n```\n\n## __init__.py Content\n```python\n\"\"\"Meld: Multi-model plan convergence orchestrator.\"\"\"\n\n__version__ = \"0.1.0\"\n```\n\n## __main__.py Content\n```python\n\"\"\"Allow running as python -m meld.\"\"\"\nfrom meld.cli import main\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Why All Stubs Upfront?\n1. **Import validation**: Ensures module structure is correct\n2. **IDE support**: Autocomplete works immediately\n3. **Parallel development**: Multiple developers can work on different modules\n4. **Test scaffolding**: Tests can be written against interfaces\n\n## Acceptance Criteria\n- [ ] All directories exist\n- [ ] All .py files exist with docstrings\n- [ ] `from meld import __version__` works\n- [ ] `python -m meld` runs (even if just prints help)\n- [ ] `from meld.providers.base import ...` imports work\n- [ ] No circular import issues","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:00:39.684833-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:00:39.684833-06:00","labels":["foundation","structure"],"dependencies":[{"issue_id":"meld-eq0.1.2","depends_on_id":"meld-eq0.1","type":"parent-child","created_at":"2026-01-15T23:00:39.68786-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.1.3","title":"1.3: Implement CLI argument parsing with argparse","description":"# Subtask 1.3: CLI Argument Parsing\n\n## What to Implement\nFull CLI argument parsing in `meld/cli.py` using argparse.\n\n## CLI Structure\n\n### Subcommands\n1. `run` (default) - Execute a meld session\n2. `doctor` - Check CLI availability and auth\n\n### Run Subcommand Flags\n\n| Flag | Type | Default | Description |\n|------|------|---------|-------------|\n| `TASK` | positional | - | Task description |\n| `--file`, `-f` | str | - | Read task from file |\n| `--prd` | str | - | Load PRD file for context |\n| `--rounds` | int | 5 | Maximum iteration rounds |\n| `--timeout` | int | 600 | Per-advisor timeout (seconds) |\n| `--output`, `-o` | str | - | Write final plan to file |\n| `--json-output` | str | - | Write JSON summary to file |\n| `--quiet`, `-q` | bool | False | No TUI, final plan to stdout |\n| `--verbose` | bool | False | Include raw advisor outputs |\n| `--resume` | str | - | Resume from run ID |\n| `--run-dir` | str | .meld/runs/ | Session artifact directory |\n| `--skip-preflight` | bool | False | Skip CLI validation |\n\n### Implementation Pattern\n\n```python\nimport argparse\nimport sys\nfrom meld import __version__\n\ndef create_parser() -\u003e argparse.ArgumentParser:\n    parser = argparse.ArgumentParser(\n        prog=\"meld\",\n        description=\"Multi-model plan convergence orchestrator\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  meld run \"Build an authentication system\"\n  meld run --file task.txt --prd requirements.md\n  echo \"Build auth\" | meld run\n  meld doctor\n\"\"\"\n    )\n    parser.add_argument(\"--version\", action=\"version\", version=f\"%(prog)s {__version__}\")\n    \n    subparsers = parser.add_subparsers(dest=\"command\", help=\"Available commands\")\n    \n    # Run subcommand\n    run_parser = subparsers.add_parser(\"run\", help=\"Execute a meld session\")\n    # ... add all flags\n    \n    # Doctor subcommand\n    doctor_parser = subparsers.add_parser(\"doctor\", help=\"Check CLI availability\")\n    \n    return parser\n\ndef main() -\u003e int:\n    parser = create_parser()\n    args = parser.parse_args()\n    \n    # Handle default command (run if no subcommand given)\n    if args.command is None:\n        args.command = \"run\"\n    \n    # Route to appropriate handler\n    if args.command == \"run\":\n        return run_command(args)\n    elif args.command == \"doctor\":\n        return doctor_command(args)\n    \n    return 0\n```\n\n## Input Mode Logic\n\n```python\ndef get_task_input(args) -\u003e str:\n    \"\"\"Get task from args, file, or stdin (in priority order).\"\"\"\n    # 1. Positional argument wins\n    if hasattr(args, 'task') and args.task:\n        return args.task\n    \n    # 2. File flag\n    if hasattr(args, 'file') and args.file:\n        with open(args.file, 'r') as f:\n            return f.read().strip()\n    \n    # 3. Stdin if piped\n    if not sys.stdin.isatty():\n        return sys.stdin.read().strip()\n    \n    # 4. No input provided\n    raise ValueError(\"No task provided. Use positional arg, --file, or pipe.\")\n```\n\n## Validation Rules\n1. `--resume` is mutually exclusive with task input\n2. `--rounds` must be \u003e= 1 and \u003c= 20\n3. `--timeout` must be \u003e= 30 and \u003c= 3600\n4. `--output` and `--json-output` directories must exist\n\n## Acceptance Criteria\n- [ ] `meld --help` shows all options\n- [ ] `meld run --help` shows run-specific options\n- [ ] `meld doctor --help` shows doctor info\n- [ ] Positional task argument works\n- [ ] `--file` reads task from file\n- [ ] Stdin detection works when piped\n- [ ] All flags parse without error\n- [ ] Invalid flag combinations rejected with clear error\n\n## Notes\n- Use argparse's built-in validation where possible\n- Custom validation in handler functions for complex rules\n- Help text should be concise but complete","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:01:16.138441-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:01:16.138441-06:00","labels":["argparse","cli","foundation"],"dependencies":[{"issue_id":"meld-eq0.1.3","depends_on_id":"meld-eq0.1","type":"parent-child","created_at":"2026-01-15T23:01:16.14204-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.1.4","title":"1.4: Implement input mode handling (arg/file/stdin/PRD)","description":"# Subtask 1.4: Input Mode Handling\n\n## What to Implement\nRobust handling of all input modes: positional argument, file, stdin, and PRD loading.\n\n## Input Priority\nWhen multiple sources are available:\n1. **Positional arg** (explicit intent)\n2. **--file** (explicit intent)\n3. **stdin** (implicit, only if piped)\n\n## Implementation\n\n```python\nimport sys\nfrom pathlib import Path\n\nclass InputError(Exception):\n    \"\"\"Raised when task input cannot be obtained.\"\"\"\n    pass\n\ndef get_task_input(args) -\u003e str:\n    \"\"\"\n    Get task from args, file, or stdin.\n    \n    Priority:\n    1. Positional argument (args.task)\n    2. File (args.file)\n    3. Stdin (only if piped, not interactive)\n    \n    Raises:\n        InputError: If no input available or file not found\n    \"\"\"\n    # Positional argument\n    if getattr(args, 'task', None):\n        return args.task.strip()\n    \n    # File input\n    if getattr(args, 'file', None):\n        path = Path(args.file)\n        if not path.exists():\n            raise InputError(f\"Task file not found: {args.file}\")\n        if not path.is_file():\n            raise InputError(f\"Not a file: {args.file}\")\n        return path.read_text().strip()\n    \n    # Stdin (only if piped)\n    if not sys.stdin.isatty():\n        content = sys.stdin.read().strip()\n        if not content:\n            raise InputError(\"Empty input from stdin\")\n        return content\n    \n    # No input available\n    raise InputError(\n        \"No task provided. Use one of:\\n\"\n        \"  meld run \\\"your task description\\\"\\n\"\n        \"  meld run --file task.txt\\n\"\n        \"  echo \\\"task\\\" | meld run\"\n    )\n\ndef load_prd(args) -\u003e str | None:\n    \"\"\"\n    Load PRD content if --prd flag provided.\n    \n    Returns:\n        PRD content as string, or None if not provided\n        \n    Raises:\n        InputError: If PRD file not found or unreadable\n    \"\"\"\n    if not getattr(args, 'prd', None):\n        return None\n    \n    path = Path(args.prd)\n    if not path.exists():\n        raise InputError(f\"PRD file not found: {args.prd}\")\n    if not path.is_file():\n        raise InputError(f\"Not a file: {args.prd}\")\n    \n    content = path.read_text().strip()\n    if not content:\n        raise InputError(f\"PRD file is empty: {args.prd}\")\n    \n    return content\n```\n\n## Edge Cases to Handle\n\n### 1. Empty Input\n```python\n# Task is whitespace only\nif not task.strip():\n    raise InputError(\"Task description cannot be empty\")\n```\n\n### 2. Very Long Input\n```python\n# v1 doesn't enforce limits, but warn for very long tasks\nMAX_TASK_CHARS = 50000\nif len(task) \u003e MAX_TASK_CHARS:\n    print(f\"Warning: Task is very long ({len(task)} chars). Consider summarizing.\", \n          file=sys.stderr)\n```\n\n### 3. Binary File Detection\n```python\n# Detect binary content (null bytes)\nif '\\x00' in content:\n    raise InputError(f\"File appears to be binary: {path}\")\n```\n\n### 4. Encoding Issues\n```python\n# Explicit UTF-8 with error handling\ntry:\n    content = path.read_text(encoding='utf-8')\nexcept UnicodeDecodeError:\n    raise InputError(f\"File is not valid UTF-8: {path}\")\n```\n\n## Resume Mode\nWhen `--resume` is provided:\n- Task input flags are ignored\n- Task is loaded from session directory\n- Validate run ID exists\n\n```python\ndef handle_resume_mode(args) -\u003e tuple[str, str | None]:\n    \"\"\"\n    Handle --resume flag.\n    \n    Returns:\n        (task, prd) loaded from session\n    \"\"\"\n    if not args.resume:\n        return None, None\n    \n    run_dir = Path(args.run_dir) / args.resume\n    if not run_dir.exists():\n        raise InputError(f\"Session not found: {args.resume}\")\n    \n    task_file = run_dir / 'task.md'\n    if not task_file.exists():\n        raise InputError(f\"Session corrupt - missing task.md: {args.resume}\")\n    \n    task = task_file.read_text().strip()\n    \n    prd_file = run_dir / 'prd.md'\n    prd = prd_file.read_text().strip() if prd_file.exists() else None\n    \n    return task, prd\n```\n\n## Acceptance Criteria\n- [ ] Positional arg: `meld run \"task\"` works\n- [ ] File input: `meld run --file task.txt` works\n- [ ] Stdin: `echo \"task\" | meld run` works\n- [ ] PRD loading: `--prd` loads content correctly\n- [ ] Missing file: Clear error message\n- [ ] Empty input: Clear error message\n- [ ] Binary file: Detected and rejected\n- [ ] Resume mode: Loads from session dir\n- [ ] Priority: Positional beats file beats stdin\n\n## Error Message Quality\nError messages should:\n1. State what went wrong\n2. Show the path/value that caused it\n3. Suggest how to fix it\n\nExample:\n```\n❌ Task file not found: requirements.txt\n   Check the path or use: meld run \"your task\"\n```","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:02:33.377264-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:02:33.377264-06:00","labels":["cli","foundation","input"],"dependencies":[{"issue_id":"meld-eq0.1.4","depends_on_id":"meld-eq0.1","type":"parent-child","created_at":"2026-01-15T23:02:33.38112-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.2","title":"Task 2: Session Manager \u0026 Persistence","description":"# Task 2: Session Manager \u0026 Persistence\n\n## Overview\nImplement the session management system that creates unique run directories, writes artifacts incrementally, and supports crash recovery via `--resume`.\n\n## Why Session Persistence Matters\n1. **Crash Recovery**: If the process dies mid-round, users can resume without re-running completed work\n2. **Debugging**: All artifacts are preserved for inspection and debugging\n3. **Audit Trail**: Complete history of what each advisor said and how the plan evolved\n4. **PRD Requirement**: \"No data loss if interrupted\"\n\n## Design Decisions\n\n### Session ID Format\n`{ISO-timestamp}-{random-6-chars}`\nExample: `2026-01-16T02-47-17Z-abc123`\n\nRationale:\n- Timestamp prefix enables sorting by creation time\n- Random suffix prevents collisions\n- Colons replaced with dashes for filesystem compatibility\n\n### Artifact Structure\n```\n.meld/\n  runs/\n    2026-01-16T02-47-17Z-abc123/\n      session.json          # Run metadata, status, config\n      task.md               # Original task input\n      prd.md                # PRD content (if provided)\n      plan.round0.md        # Initial plan (before feedback)\n      plan.round1.md        # Plan after round 1\n      advisor.claude.round1.md\n      advisor.gemini.round1.md\n      advisor.codex.round1.md\n      plan.round2.md\n      advisor.claude.round2.md\n      ...\n      final-plan.md         # Final output (on completion)\n      events.jsonl          # Structured event log\n```\n\n### Write Strategy: Incremental + Atomic\n1. Write artifacts immediately after each operation completes\n2. Use atomic writes (write to temp, then rename)\n3. Update session.json after each checkpoint\n\n### Why JSONL for Events?\n- Append-only format survives crashes\n- Each line is independently parseable\n- Easy to tail -f for debugging\n- Common format for log analysis tools\n\n## Technical Requirements\n\n### Session State Machine\n```\nPENDING → IN_PROGRESS → COMPLETED\n                 ↓\n            INTERRUPTED → (resume) → IN_PROGRESS\n                 ↓\n               FAILED\n```\n\n### session.json Schema\n```json\n{\n  \"id\": \"2026-01-16T02-47-17Z-abc123\",\n  \"status\": \"in_progress\",\n  \"current_round\": 2,\n  \"interrupted_at\": null,\n  \"max_rounds\": 5,\n  \"started\": \"2026-01-16T02:47:17Z\",\n  \"updated\": \"2026-01-16T02:52:00Z\",\n  \"config\": {\n    \"timeout\": 600,\n    \"prd_file\": \"requirements.md\"\n  },\n  \"advisors\": {\n    \"claude\": \"completed\",\n    \"gemini\": \"failed\",\n    \"codex\": \"completed\"\n  },\n  \"convergence\": {\n    \"status\": \"continuing\",\n    \"open_items\": 2,\n    \"diff_ratio\": 0.08\n  }\n}\n```\n\n### Key Operations\n1. `create_session()` - Initialize new run directory\n2. `load_session(run_id)` - Load existing session for resume\n3. `write_artifact(name, content)` - Write file atomically\n4. `update_status(status, **fields)` - Update session.json\n5. `append_event(event)` - Append to events.jsonl\n6. `get_last_checkpoint()` - Find resume point\n\n## Acceptance Criteria\n- [ ] Run directory created with unique ID\n- [ ] task.md and prd.md written on session start\n- [ ] plan.roundN.md written after each plan generation\n- [ ] advisor.*.roundN.md written after each advisor response\n- [ ] session.json updated after each operation\n- [ ] events.jsonl appended to correctly\n- [ ] Resume loads session state correctly\n- [ ] Atomic writes prevent corruption\n- [ ] Directory permissions set correctly (0o755)\n\n## Edge Cases\n1. **Disk full**: Detect and report clearly\n2. **Permission denied**: Check at session start\n3. **Concurrent access**: Use file locking\n4. **Unicode filenames**: Avoid in run IDs","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:03:29.874725-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:03:29.874725-06:00","labels":["foundation","persistence","phase-1","session"],"dependencies":[{"issue_id":"meld-eq0.2","depends_on_id":"meld-eq0","type":"parent-child","created_at":"2026-01-15T23:03:29.878171-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.2.1","title":"2.1: Implement session ID generation and directory creation","description":"# Subtask 2.1: Session ID \u0026 Directory Creation\n\n## What to Implement\nGenerate unique session IDs and create the run directory structure.\n\n## Session ID Format\n`{ISO-timestamp}-{random-6-chars}`\n\n### Implementation\n\n```python\nimport secrets\nfrom datetime import datetime, timezone\nfrom pathlib import Path\n\ndef generate_session_id() -\u003e str:\n    \"\"\"\n    Generate unique session ID.\n    \n    Format: YYYY-MM-DDTHH-MM-SSZ-xxxxxx\n    Example: 2026-01-16T02-47-17Z-abc123\n    \n    Uses:\n    - UTC timestamp for consistency\n    - Dashes instead of colons for filesystem compatibility\n    - 6 random chars (36^6 = 2 billion combinations)\n    \"\"\"\n    timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H-%M-%SZ')\n    random_suffix = secrets.token_hex(3)  # 6 hex chars\n    return f\"{timestamp}-{random_suffix}\"\n\ndef create_session_directory(\n    session_id: str,\n    base_dir: Path | str = '.meld/runs'\n) -\u003e Path:\n    \"\"\"\n    Create session directory with proper structure.\n    \n    Args:\n        session_id: Unique session identifier\n        base_dir: Base directory for runs (default: .meld/runs)\n        \n    Returns:\n        Path to created session directory\n        \n    Raises:\n        OSError: If directory creation fails\n    \"\"\"\n    base = Path(base_dir)\n    session_dir = base / session_id\n    \n    # Create with parents and explicit permissions\n    session_dir.mkdir(parents=True, exist_ok=False, mode=0o755)\n    \n    return session_dir\n```\n\n## Directory Structure Created\n```\n.meld/\n  runs/\n    {session_id}/    # Empty initially, populated by other operations\n```\n\n## Error Handling\n\n### Directory Already Exists\nShould never happen due to random suffix, but handle gracefully:\n```python\nif session_dir.exists():\n    # Regenerate with new random suffix\n    return create_session_directory(generate_session_id(), base_dir)\n```\n\n### Permission Denied\n```python\ntry:\n    session_dir.mkdir(...)\nexcept PermissionError:\n    raise SessionError(f\"Cannot create session directory: permission denied at {base_dir}\")\n```\n\n### Disk Full\n```python\nexcept OSError as e:\n    if e.errno == errno.ENOSPC:\n        raise SessionError(\"Cannot create session: disk full\")\n    raise\n```\n\n## Acceptance Criteria\n- [ ] Session IDs are unique (test with 1000 rapid generations)\n- [ ] Timestamp portion is valid ISO format\n- [ ] Random suffix is 6 hex characters\n- [ ] Directory created with 755 permissions\n- [ ] Parent directories created if needed\n- [ ] Clear error on permission denied\n- [ ] Clear error on disk full\n\n## Testing Strategy\n```python\ndef test_session_id_uniqueness():\n    ids = [generate_session_id() for _ in range(1000)]\n    assert len(ids) == len(set(ids)), \"Duplicate session IDs generated\"\n\ndef test_session_id_format():\n    sid = generate_session_id()\n    # Should match: 2026-01-16T02-47-17Z-abc123\n    import re\n    pattern = r'^\\d{4}-\\d{2}-\\d{2}T\\d{2}-\\d{2}-\\d{2}Z-[a-f0-9]{6}$'\n    assert re.match(pattern, sid)\n```","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:05:00.743615-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:05:00.743615-06:00","labels":["foundation","session"],"dependencies":[{"issue_id":"meld-eq0.2.1","depends_on_id":"meld-eq0.2","type":"parent-child","created_at":"2026-01-15T23:05:00.744432-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.2.2","title":"2.2: Implement atomic file writing for artifacts","description":"# Subtask 2.2: Atomic File Writing\n\n## What to Implement\nSafe, atomic file writing that prevents corruption from crashes or concurrent access.\n\n## Why Atomic Writes?\nIf the process crashes while writing:\n- **Non-atomic**: File may be partially written, corrupted\n- **Atomic**: Either old content exists or new content exists, never partial\n\n## Implementation Pattern\n\n```python\nimport os\nimport tempfile\nfrom pathlib import Path\n\ndef write_artifact(\n    session_dir: Path,\n    filename: str,\n    content: str,\n    encoding: str = 'utf-8'\n) -\u003e Path:\n    \"\"\"\n    Write artifact file atomically.\n    \n    Uses write-to-temp-then-rename pattern for atomicity.\n    \n    Args:\n        session_dir: Session directory path\n        filename: Name of file to write\n        content: Content to write\n        encoding: Text encoding (default: utf-8)\n        \n    Returns:\n        Path to written file\n        \n    Raises:\n        OSError: If write fails\n    \"\"\"\n    target_path = session_dir / filename\n    \n    # Create temp file in same directory (same filesystem for atomic rename)\n    fd, temp_path = tempfile.mkstemp(\n        dir=session_dir,\n        prefix=f'.{filename}.',\n        suffix='.tmp'\n    )\n    \n    try:\n        # Write content to temp file\n        with os.fdopen(fd, 'w', encoding=encoding) as f:\n            f.write(content)\n            f.flush()\n            os.fsync(f.fileno())  # Force write to disk\n        \n        # Atomic rename\n        os.rename(temp_path, target_path)\n        \n        return target_path\n        \n    except Exception:\n        # Clean up temp file on failure\n        try:\n            os.unlink(temp_path)\n        except OSError:\n            pass\n        raise\n```\n\n## Artifact Types\n\n### Text Artifacts\n- `task.md`: Original task input\n- `prd.md`: PRD content\n- `plan.round{N}.md`: Plan after round N\n- `advisor.{name}.round{N}.md`: Advisor feedback\n- `final-plan.md`: Final output\n\n### JSON Artifacts\n- `session.json`: Session metadata\n\n### JSONL Artifacts (append-only)\n- `events.jsonl`: Event log\n\n## Append-Only JSONL Writing\n\n```python\nimport json\nimport fcntl\n\ndef append_event(session_dir: Path, event: dict) -\u003e None:\n    \"\"\"\n    Append event to events.jsonl with file locking.\n    \n    Each event is a single JSON line. File locking prevents\n    concurrent append corruption.\n    \n    Args:\n        session_dir: Session directory path\n        event: Event dictionary to append\n    \"\"\"\n    events_path = session_dir / 'events.jsonl'\n    \n    # Add timestamp if not present\n    if 'timestamp' not in event:\n        event['timestamp'] = datetime.now(timezone.utc).isoformat()\n    \n    line = json.dumps(event, ensure_ascii=False) + '\\n'\n    \n    with open(events_path, 'a', encoding='utf-8') as f:\n        # Acquire exclusive lock\n        fcntl.flock(f.fileno(), fcntl.LOCK_EX)\n        try:\n            f.write(line)\n            f.flush()\n            os.fsync(f.fileno())\n        finally:\n            fcntl.flock(f.fileno(), fcntl.LOCK_UN)\n```\n\n## Event Schema\n\n```json\n{\"timestamp\": \"2026-01-16T02:47:17Z\", \"event\": \"session_started\", \"session_id\": \"...\"}\n{\"timestamp\": \"2026-01-16T02:47:20Z\", \"event\": \"plan_generated\", \"round\": 0}\n{\"timestamp\": \"2026-01-16T02:48:00Z\", \"event\": \"advisor_started\", \"advisor\": \"claude\", \"round\": 1}\n{\"timestamp\": \"2026-01-16T02:49:30Z\", \"event\": \"advisor_completed\", \"advisor\": \"claude\", \"round\": 1, \"duration_ms\": 90000}\n{\"timestamp\": \"2026-01-16T02:49:35Z\", \"event\": \"advisor_failed\", \"advisor\": \"gemini\", \"round\": 1, \"error\": \"timeout\"}\n```\n\n## Acceptance Criteria\n- [ ] Files written atomically (verify with crash simulation)\n- [ ] Temp files cleaned up on failure\n- [ ] fsync forces data to disk\n- [ ] events.jsonl is append-only\n- [ ] File locking prevents corruption\n- [ ] UTF-8 encoding used consistently\n- [ ] No partial writes possible\n\n## Testing Strategy\n```python\ndef test_atomic_write_on_crash():\n    \"\"\"Simulate crash during write, verify no corruption.\"\"\"\n    # Write initial content\n    write_artifact(session_dir, 'test.md', 'original content')\n    \n    # Simulate crash during second write (mock os.rename to fail)\n    with patch('os.rename', side_effect=OSError(\"Simulated crash\")):\n        with pytest.raises(OSError):\n            write_artifact(session_dir, 'test.md', 'new content')\n    \n    # Original should still exist\n    assert (session_dir / 'test.md').read_text() == 'original content'\n```","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:06:00.395037-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:06:00.395037-06:00","labels":["foundation","io","session"],"dependencies":[{"issue_id":"meld-eq0.2.2","depends_on_id":"meld-eq0.2","type":"parent-child","created_at":"2026-01-15T23:06:00.395814-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.2.3","title":"2.3: Implement session.json management","description":"# Subtask 2.3: session.json Management\n\n## What to Implement\nCreate and update the session.json metadata file that tracks run state.\n\n## session.json Schema\n\n```python\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any\nimport json\n\nclass SessionStatus(str, Enum):\n    PENDING = 'pending'\n    IN_PROGRESS = 'in_progress'\n    COMPLETED = 'completed'\n    FAILED = 'failed'\n    INTERRUPTED = 'interrupted'\n\nclass AdvisorStatus(str, Enum):\n    PENDING = 'pending'\n    RUNNING = 'running'\n    COMPLETED = 'completed'\n    FAILED = 'failed'\n    SKIPPED = 'skipped'\n\nclass InterruptedAt(str, Enum):\n    PLANNING = 'planning'\n    FEEDBACK = 'feedback'\n    SYNTHESIS = 'synthesis'\n\n@dataclass\nclass SessionConfig:\n    timeout: int = 600\n    max_rounds: int = 5\n    prd_file: str | None = None\n    skip_preflight: bool = False\n    quiet: bool = False\n    verbose: bool = False\n\n@dataclass\nclass ConvergenceState:\n    status: str = 'continuing'  # 'converged' or 'continuing'\n    open_items: int = 0\n    changes_made: int = 0\n    diff_ratio: float = 0.0\n    rationale: str = ''\n\n@dataclass\nclass SessionState:\n    id: str\n    status: SessionStatus = SessionStatus.PENDING\n    current_round: int = 0\n    interrupted_at: InterruptedAt | None = None\n    started: str = ''  # ISO datetime\n    updated: str = ''  # ISO datetime\n    config: SessionConfig = field(default_factory=SessionConfig)\n    advisors: dict[str, AdvisorStatus] = field(default_factory=lambda: {\n        'claude': AdvisorStatus.PENDING,\n        'gemini': AdvisorStatus.PENDING,\n        'codex': AdvisorStatus.PENDING,\n    })\n    convergence: ConvergenceState = field(default_factory=ConvergenceState)\n    \n    def to_dict(self) -\u003e dict[str, Any]:\n        \"\"\"Convert to JSON-serializable dict.\"\"\"\n        d = asdict(self)\n        # Convert enums to strings\n        d['status'] = self.status.value\n        d['interrupted_at'] = self.interrupted_at.value if self.interrupted_at else None\n        d['advisors'] = {k: v.value for k, v in self.advisors.items()}\n        return d\n    \n    @classmethod\n    def from_dict(cls, d: dict) -\u003e 'SessionState':\n        \"\"\"Create from dict (for loading).\"\"\"\n        # Convert strings back to enums\n        d['status'] = SessionStatus(d['status'])\n        if d.get('interrupted_at'):\n            d['interrupted_at'] = InterruptedAt(d['interrupted_at'])\n        d['advisors'] = {k: AdvisorStatus(v) for k, v in d['advisors'].items()}\n        d['config'] = SessionConfig(**d['config'])\n        d['convergence'] = ConvergenceState(**d['convergence'])\n        return cls(**d)\n```\n\n## Session Manager Class\n\n```python\nclass SessionManager:\n    \"\"\"Manages session lifecycle and persistence.\"\"\"\n    \n    def __init__(self, session_dir: Path, state: SessionState):\n        self.session_dir = session_dir\n        self.state = state\n        self._json_path = session_dir / 'session.json'\n    \n    @classmethod\n    def create_new(\n        cls,\n        base_dir: Path,\n        config: SessionConfig,\n    ) -\u003e 'SessionManager':\n        \"\"\"Create a new session.\"\"\"\n        session_id = generate_session_id()\n        session_dir = create_session_directory(session_id, base_dir)\n        \n        now = datetime.now(timezone.utc).isoformat()\n        state = SessionState(\n            id=session_id,\n            status=SessionStatus.PENDING,\n            started=now,\n            updated=now,\n            config=config,\n        )\n        \n        manager = cls(session_dir, state)\n        manager._write_state()\n        return manager\n    \n    @classmethod\n    def load(cls, base_dir: Path, session_id: str) -\u003e 'SessionManager':\n        \"\"\"Load existing session for resume.\"\"\"\n        session_dir = base_dir / session_id\n        json_path = session_dir / 'session.json'\n        \n        if not json_path.exists():\n            raise SessionError(f\"Session not found: {session_id}\")\n        \n        with open(json_path, 'r') as f:\n            data = json.load(f)\n        \n        state = SessionState.from_dict(data)\n        return cls(session_dir, state)\n    \n    def update_status(self, status: SessionStatus, **kwargs) -\u003e None:\n        \"\"\"Update session status and any additional fields.\"\"\"\n        self.state.status = status\n        self.state.updated = datetime.now(timezone.utc).isoformat()\n        \n        for key, value in kwargs.items():\n            if hasattr(self.state, key):\n                setattr(self.state, key, value)\n        \n        self._write_state()\n    \n    def _write_state(self) -\u003e None:\n        \"\"\"Write session.json atomically.\"\"\"\n        content = json.dumps(self.state.to_dict(), indent=2)\n        write_artifact(self.session_dir, 'session.json', content)\n```\n\n## State Transitions\n\n```\ncreate_new() → PENDING\nstart_run() → IN_PROGRESS\ncomplete_round() → IN_PROGRESS (update current_round)\nmark_converged() → COMPLETED\nmark_failed(error) → FAILED\nhandle_interrupt() → INTERRUPTED (set interrupted_at)\nresume() → IN_PROGRESS (clear interrupted_at)\n```\n\n## Acceptance Criteria\n- [ ] session.json created on new session\n- [ ] All fields serialize correctly\n- [ ] Status transitions work correctly\n- [ ] Updated timestamp changes on each update\n- [ ] Load from existing session works\n- [ ] Invalid session ID raises clear error\n- [ ] Dataclasses round-trip correctly (save → load)\n\n## Testing Strategy\n```python\ndef test_session_round_trip():\n    \"\"\"Session state survives save and load.\"\"\"\n    manager = SessionManager.create_new(tmp_dir, SessionConfig())\n    session_id = manager.state.id\n    \n    manager.update_status(SessionStatus.IN_PROGRESS, current_round=2)\n    \n    # Reload\n    loaded = SessionManager.load(tmp_dir, session_id)\n    assert loaded.state.status == SessionStatus.IN_PROGRESS\n    assert loaded.state.current_round == 2\n```","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:06:48.792881-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:06:48.792881-06:00","labels":["foundation","session","state"],"dependencies":[{"issue_id":"meld-eq0.2.3","depends_on_id":"meld-eq0.2","type":"parent-child","created_at":"2026-01-15T23:06:48.795245-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.2.4","title":"2.4: Implement --resume checkpoint recovery","description":"# Subtask 2.4: Resume/Checkpoint Recovery\n\n## What to Implement\nLogic to resume an interrupted session from the last completed checkpoint.\n\n## Resume Strategy\n\n### Checkpoint Granularity\nA checkpoint is saved after:\n1. Initial plan generation (round 0)\n2. All advisors complete for a round\n3. Synthesis complete for a round\n\n### Resume Points\nThe session can resume from:\n- **planning**: Re-generate initial plan\n- **feedback**: Re-run advisor feedback for current round\n- **synthesis**: Re-synthesize feedback into plan\n\n### Finding Resume Point\n\n```python\nfrom pathlib import Path\nfrom typing import Tuple\n\ndef find_resume_point(session_dir: Path) -\u003e Tuple[str, int]:\n    \"\"\"\n    Determine where to resume based on artifacts present.\n    \n    Returns:\n        (phase, round_number) - where to resume\n        \n    Logic:\n    1. Find highest round number with plan.roundN.md\n    2. Check if all advisors completed for that round\n    3. Return appropriate resume point\n    \"\"\"\n    # Find all plan files\n    plan_files = sorted(session_dir.glob('plan.round*.md'))\n    \n    if not plan_files:\n        # No plans yet, start from beginning\n        return ('planning', 0)\n    \n    # Get highest round with plan\n    latest_plan = plan_files[-1]\n    round_num = int(latest_plan.stem.split('round')[1])\n    \n    # Check if advisors completed for next round\n    advisors = ['claude', 'gemini', 'codex']\n    next_round = round_num + 1\n    \n    advisor_files = [\n        session_dir / f'advisor.{name}.round{next_round}.md'\n        for name in advisors\n    ]\n    \n    # Count how many advisor files exist\n    existing_advisors = sum(1 for f in advisor_files if f.exists())\n    \n    if existing_advisors == 0:\n        # No advisor feedback for next round, need to get feedback\n        return ('feedback', next_round)\n    elif existing_advisors \u003c 3:\n        # Partial advisor feedback, resume feedback (will handle existing)\n        return ('feedback', next_round)\n    else:\n        # All advisor feedback exists, need synthesis\n        return ('synthesis', next_round)\n```\n\n## Resume Handler\n\n```python\nclass ResumeHandler:\n    \"\"\"Handles session resume logic.\"\"\"\n    \n    def __init__(self, session_manager: SessionManager):\n        self.manager = session_manager\n        self.session_dir = session_manager.session_dir\n    \n    def prepare_resume(self) -\u003e dict:\n        \"\"\"\n        Prepare session for resumption.\n        \n        Returns:\n            dict with resume context:\n            {\n                'phase': 'feedback',\n                'round': 2,\n                'task': 'original task...',\n                'prd': 'prd content...' or None,\n                'current_plan': 'latest plan content...',\n                'existing_feedback': {'claude': '...', 'gemini': None, 'codex': '...'},\n            }\n        \"\"\"\n        phase, round_num = find_resume_point(self.session_dir)\n        \n        # Load task and PRD\n        task = (self.session_dir / 'task.md').read_text()\n        prd_path = self.session_dir / 'prd.md'\n        prd = prd_path.read_text() if prd_path.exists() else None\n        \n        # Load current plan (last completed)\n        if round_num == 0 and phase == 'planning':\n            current_plan = None\n        else:\n            plan_round = round_num - 1 if phase == 'feedback' else round_num\n            current_plan = (self.session_dir / f'plan.round{plan_round}.md').read_text()\n        \n        # Load existing feedback for this round (if any)\n        existing_feedback = {}\n        if phase in ('feedback', 'synthesis'):\n            for advisor in ['claude', 'gemini', 'codex']:\n                path = self.session_dir / f'advisor.{advisor}.round{round_num}.md'\n                existing_feedback[advisor] = path.read_text() if path.exists() else None\n        \n        # Update session state\n        self.manager.state.interrupted_at = None  # Clear interrupt\n        self.manager.state.status = SessionStatus.IN_PROGRESS\n        self.manager.state.current_round = round_num\n        self.manager._write_state()\n        \n        return {\n            'phase': phase,\n            'round': round_num,\n            'task': task,\n            'prd': prd,\n            'current_plan': current_plan,\n            'existing_feedback': existing_feedback,\n        }\n```\n\n## Validation Before Resume\n\n```python\ndef validate_session_for_resume(session_dir: Path) -\u003e list[str]:\n    \"\"\"\n    Check session is valid for resume.\n    \n    Returns:\n        List of validation errors (empty if valid)\n    \"\"\"\n    errors = []\n    \n    # Must have session.json\n    if not (session_dir / 'session.json').exists():\n        errors.append('Missing session.json - session may be corrupted')\n    \n    # Must have task.md\n    if not (session_dir / 'task.md').exists():\n        errors.append('Missing task.md - cannot resume without original task')\n    \n    # Load session state\n    try:\n        with open(session_dir / 'session.json') as f:\n            state = json.load(f)\n    except json.JSONDecodeError:\n        errors.append('Corrupted session.json - cannot parse')\n        return errors\n    \n    # Check status allows resume\n    status = state.get('status')\n    if status == 'completed':\n        errors.append('Session already completed - nothing to resume')\n    \n    return errors\n```\n\n## Acceptance Criteria\n- [ ] Correctly identifies resume point from artifacts\n- [ ] Loads task and PRD from session\n- [ ] Loads current plan state\n- [ ] Identifies which advisors completed\n- [ ] Clears interrupted_at flag on resume\n- [ ] Validates session before attempting resume\n- [ ] Clear error if session corrupted\n- [ ] Clear error if session already complete\n\n## Edge Cases\n1. **No artifacts**: Resume from beginning\n2. **Partial advisor files**: Resume feedback, skip completed advisors\n3. **Corrupted session.json**: Error with recovery suggestion\n4. **Already completed**: Error indicating nothing to resume","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:08:09.95309-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:08:09.95309-06:00","labels":["foundation","resume","session"],"dependencies":[{"issue_id":"meld-eq0.2.4","depends_on_id":"meld-eq0.2","type":"parent-child","created_at":"2026-01-15T23:08:09.956486-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.3","title":"Task 3: Provider Adapter Interface","description":"# Task 3: Provider Adapter Interface\n\n## Overview\nDesign and implement the abstract base class for provider adapters that encapsulates CLI-specific behavior for Claude, Gemini, and Codex CLIs.\n\n## Why an Adapter Layer?\n\n### Problem: CLI Drift\nEach AI CLI tool:\n- Has different flags and options\n- May change between versions\n- Has different output formats\n- Handles errors differently\n- Has different authentication mechanisms\n\n### Solution: Adapter Pattern\nThe adapter pattern:\n1. **Encapsulates** CLI-specific details in one place\n2. **Normalizes** output to a consistent format\n3. **Isolates** changes when CLIs update\n4. **Enables** testing with mock adapters\n5. **Supports** adding new providers easily\n\n## Design Principles\n\n### Single Responsibility\nEach adapter handles exactly one CLI:\n- Command construction\n- Execution and streaming\n- Output parsing\n- Error categorization\n\n### Consistent Interface\nAll adapters expose the same async interface:\n```python\nasync def run(prompt: str) -\u003e AdvisorResult\nasync def stream(prompt: str) -\u003e AsyncIterator[StreamEvent]\nasync def check_available() -\u003e AvailabilityResult\n```\n\n### Streaming First\nAll adapters stream output for real-time TUI updates.\nFull response is assembled from stream for artifact storage.\n\n## Technical Requirements\n\n### AdvisorResult Data Model\n```python\n@dataclass\nclass AdvisorResult:\n    \"\"\"Result from an advisor invocation.\"\"\"\n    provider: str          # 'claude', 'gemini', 'codex'\n    success: bool          # Whether invocation succeeded\n    content: str           # Full response text\n    duration_ms: int       # Execution time\n    error: AdvisorError | None  # Error info if failed\n    metadata: dict         # Provider-specific metadata\n```\n\n### StreamEvent Data Model\n```python\n@dataclass\nclass StreamEvent:\n    \"\"\"Event from streaming output.\"\"\"\n    type: StreamEventType  # 'text', 'error', 'done'\n    content: str           # Text chunk or error message\n    timestamp: float       # Time since start (seconds)\n```\n\n### AdvisorError Categories\n```python\nclass AdvisorError(Enum):\n    CLI_NOT_FOUND = auto()     # CLI binary not installed\n    AUTH_FAILED = auto()       # Not authenticated\n    TIMEOUT = auto()           # Response took too long\n    RATE_LIMITED = auto()      # API quota exceeded\n    NETWORK_ERROR = auto()     # Connection issues\n    PARSE_ERROR = auto()       # Unexpected output format\n    INTERNAL_ERROR = auto()    # CLI internal error\n```\n\n### Base Adapter Class\n```python\nfrom abc import ABC, abstractmethod\n\nclass ProviderAdapter(ABC):\n    \"\"\"Abstract base class for AI CLI adapters.\"\"\"\n    \n    name: str  # 'claude', 'gemini', 'codex'\n    \n    @abstractmethod\n    async def run(\n        self,\n        prompt: str,\n        timeout: float = 600.0,\n        cwd: Path | None = None,\n    ) -\u003e AdvisorResult:\n        \"\"\"\n        Run CLI with prompt and return full result.\n        \n        Args:\n            prompt: The prompt to send\n            timeout: Maximum execution time in seconds\n            cwd: Working directory for CLI (default: current)\n            \n        Returns:\n            AdvisorResult with response or error\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def stream(\n        self,\n        prompt: str,\n        timeout: float = 600.0,\n        cwd: Path | None = None,\n    ) -\u003e AsyncIterator[StreamEvent]:\n        \"\"\"\n        Stream CLI output for real-time display.\n        \n        Yields:\n            StreamEvent objects as output arrives\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def check_available(self) -\u003e AvailabilityResult:\n        \"\"\"\n        Check if CLI is installed and authenticated.\n        \n        Returns:\n            AvailabilityResult with status and any issues\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def build_command(self, prompt: str) -\u003e list[str]:\n        \"\"\"\n        Build CLI command from prompt.\n        \n        Returns:\n            Command as list of strings for subprocess\n        \"\"\"\n        pass\n```\n\n## Subprocess Runner\n\n```python\nasync def run_subprocess(\n    cmd: list[str],\n    timeout: float,\n    cwd: Path | None = None,\n) -\u003e tuple[str, str, int]:\n    \"\"\"\n    Run subprocess with timeout and output capture.\n    \n    Returns:\n        (stdout, stderr, return_code)\n    \"\"\"\n    process = await asyncio.create_subprocess_exec(\n        *cmd,\n        cwd=cwd or os.getcwd(),\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.PIPE,\n    )\n    \n    try:\n        stdout, stderr = await asyncio.wait_for(\n            process.communicate(),\n            timeout=timeout\n        )\n        return stdout.decode(), stderr.decode(), process.returncode\n    except asyncio.TimeoutError:\n        process.kill()\n        await process.wait()\n        raise TimeoutError(f\"Process exceeded {timeout}s timeout\")\n```\n\n## Acceptance Criteria\n- [ ] ProviderAdapter ABC defined with all methods\n- [ ] AdvisorResult dataclass complete\n- [ ] StreamEvent dataclass complete\n- [ ] AdvisorError enum covers all cases\n- [ ] run_subprocess handles timeout correctly\n- [ ] All types have proper type hints\n- [ ] Docstrings explain behavior\n\n## Notes for Implementation\n- Use `typing.AsyncIterator` for stream return type\n- Use `abc.ABC` and `@abstractmethod` for base class\n- Prefer `asyncio.create_subprocess_exec` over `shell=True`\n- Always set explicit `cwd` for reproducibility","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:09:38.110548-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:09:38.110548-06:00","labels":["adapter","foundation","interface","phase-1"],"dependencies":[{"issue_id":"meld-eq0.3","depends_on_id":"meld-eq0","type":"parent-child","created_at":"2026-01-15T23:09:38.118605-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.3.1","title":"3.1: Define data models (AdvisorResult, StreamEvent, errors)","description":"# Subtask 3.1: Provider Data Models\n\n## What to Implement\nAll data classes and enums used by the provider adapter interface.\n\n## Location\n`meld/models.py` - Central location for all data models.\n\n## Implementations\n\n### AdvisorError Enum\n```python\nfrom enum import Enum, auto\n\nclass AdvisorError(Enum):\n    \"\"\"Categories of errors from advisor CLI invocations.\n    \n    These categories determine retry behavior and user messaging.\n    \"\"\"\n    CLI_NOT_FOUND = auto()     # CLI binary not installed\n    AUTH_FAILED = auto()       # Not authenticated to API\n    TIMEOUT = auto()           # Response exceeded time limit\n    RATE_LIMITED = auto()      # API quota exceeded\n    NETWORK_ERROR = auto()     # Connection/DNS issues\n    PARSE_ERROR = auto()       # Unexpected output format\n    INTERNAL_ERROR = auto()    # CLI internal failure\n    UNKNOWN = auto()           # Unrecognized error\n```\n\n### StreamEventType Enum\n```python\nclass StreamEventType(Enum):\n    \"\"\"Types of events in streaming output.\"\"\"\n    TEXT = 'text'       # Regular text chunk\n    ERROR = 'error'     # Error message\n    DONE = 'done'       # Stream complete\n    STATUS = 'status'   # Status update (e.g., \"thinking...\")\n```\n\n### StreamEvent Dataclass\n```python\nfrom dataclasses import dataclass\n\n@dataclass\nclass StreamEvent:\n    \"\"\"\n    Event from streaming CLI output.\n    \n    Used by TUI to display real-time progress.\n    \n    Attributes:\n        type: Type of event (text, error, done)\n        content: Text content or error message\n        timestamp: Seconds since stream started\n    \"\"\"\n    type: StreamEventType\n    content: str\n    timestamp: float  # Time since start in seconds\n    \n    @classmethod\n    def text(cls, content: str, timestamp: float) -\u003e 'StreamEvent':\n        return cls(StreamEventType.TEXT, content, timestamp)\n    \n    @classmethod\n    def error(cls, message: str, timestamp: float) -\u003e 'StreamEvent':\n        return cls(StreamEventType.ERROR, message, timestamp)\n    \n    @classmethod\n    def done(cls, timestamp: float) -\u003e 'StreamEvent':\n        return cls(StreamEventType.DONE, '', timestamp)\n```\n\n### AdvisorResult Dataclass\n```python\n@dataclass\nclass AdvisorResult:\n    \"\"\"\n    Result from an advisor CLI invocation.\n    \n    Captures both successful responses and failures\n    in a uniform structure.\n    \n    Attributes:\n        provider: Name of the provider ('claude', 'gemini', 'codex')\n        success: Whether invocation succeeded\n        content: Full response text (empty on failure)\n        duration_ms: Execution time in milliseconds\n        error: Error category if failed\n        error_message: Human-readable error description\n        metadata: Provider-specific additional data\n    \"\"\"\n    provider: str\n    success: bool\n    content: str\n    duration_ms: int\n    error: AdvisorError | None = None\n    error_message: str = ''\n    metadata: dict = field(default_factory=dict)\n    \n    @classmethod\n    def success_result(\n        cls,\n        provider: str,\n        content: str,\n        duration_ms: int,\n        metadata: dict | None = None,\n    ) -\u003e 'AdvisorResult':\n        \"\"\"Create a successful result.\"\"\"\n        return cls(\n            provider=provider,\n            success=True,\n            content=content,\n            duration_ms=duration_ms,\n            metadata=metadata or {},\n        )\n    \n    @classmethod\n    def failure_result(\n        cls,\n        provider: str,\n        error: AdvisorError,\n        error_message: str,\n        duration_ms: int,\n    ) -\u003e 'AdvisorResult':\n        \"\"\"Create a failure result.\"\"\"\n        return cls(\n            provider=provider,\n            success=False,\n            content='',\n            duration_ms=duration_ms,\n            error=error,\n            error_message=error_message,\n        )\n```\n\n### AvailabilityResult Dataclass\n```python\n@dataclass\nclass AvailabilityResult:\n    \"\"\"\n    Result from checking CLI availability.\n    \n    Used by preflight checks and meld doctor.\n    \n    Attributes:\n        provider: Name of the provider\n        available: Whether CLI is installed and accessible\n        authenticated: Whether auth is configured (if checkable)\n        version: CLI version string (if available)\n        error: Error if not available\n        install_hint: How to install if missing\n    \"\"\"\n    provider: str\n    available: bool\n    authenticated: bool | None = None  # None if can't check\n    version: str = ''\n    error: str = ''\n    install_hint: str = ''\n```\n\n## Acceptance Criteria\n- [ ] All enums defined with appropriate values\n- [ ] All dataclasses have complete type hints\n- [ ] Factory methods work correctly\n- [ ] Docstrings explain purpose and usage\n- [ ] Can import from meld.models\n- [ ] No circular imports\n\n## Testing Strategy\n```python\ndef test_advisor_result_success():\n    result = AdvisorResult.success_result(\n        provider='claude',\n        content='Plan content here',\n        duration_ms=5000,\n    )\n    assert result.success\n    assert result.error is None\n\ndef test_advisor_result_failure():\n    result = AdvisorResult.failure_result(\n        provider='gemini',\n        error=AdvisorError.TIMEOUT,\n        error_message='Exceeded 600s timeout',\n        duration_ms=600000,\n    )\n    assert not result.success\n    assert result.error == AdvisorError.TIMEOUT\n```","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:10:25.105587-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:10:25.105587-06:00","labels":["foundation","models","types"],"dependencies":[{"issue_id":"meld-eq0.3.1","depends_on_id":"meld-eq0.3","type":"parent-child","created_at":"2026-01-15T23:10:25.109581-06:00","created_by":"Michael Fork"}]}
{"id":"meld-eq0.3.2","title":"3.2: Implement ProviderAdapter abstract base class","description":"# Subtask 3.2: ProviderAdapter Abstract Base Class\n\n## What to Implement\nThe abstract base class that all provider adapters must implement.\n\n## Location\n`meld/providers/base.py`\n\n## Implementation\n\n```python\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom typing import AsyncIterator\nimport asyncio\nimport os\nimport time\n\nfrom meld.models import (\n    AdvisorResult,\n    AdvisorError,\n    StreamEvent,\n    StreamEventType,\n    AvailabilityResult,\n)\n\n\nclass ProviderAdapter(ABC):\n    \"\"\"\n    Abstract base class for AI CLI provider adapters.\n    \n    Each adapter encapsulates the specifics of one CLI tool:\n    - Command construction with correct flags\n    - Output parsing and normalization\n    - Error categorization\n    - Streaming support\n    \n    Subclasses must implement:\n    - name: Provider identifier\n    - build_command(): Construct CLI command\n    - parse_output(): Parse CLI output\n    - categorize_error(): Map errors to categories\n    - check_available(): Verify CLI is ready\n    \n    The base class provides:\n    - run(): Full execution with result\n    - stream(): Streaming execution\n    - Subprocess management and timeout handling\n    \n    Example:\n        class ClaudeAdapter(ProviderAdapter):\n            name = 'claude'\n            \n            def build_command(self, prompt: str) -\u003e list[str]:\n                return ['claude', '-p', prompt, '--output-format', 'text']\n    \"\"\"\n    \n    name: str  # Must be set by subclass\n    \n    @abstractmethod\n    def build_command(self, prompt: str) -\u003e list[str]:\n        \"\"\"\n        Build CLI command for the given prompt.\n        \n        Args:\n            prompt: The prompt text to send to the AI\n            \n        Returns:\n            List of command parts for subprocess\n            \n        Example:\n            ['claude', '-p', 'What is 2+2?', '--output-format', 'text']\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def parse_output(self, stdout: str, stderr: str) -\u003e str:\n        \"\"\"\n        Parse CLI output to extract response content.\n        \n        Args:\n            stdout: Standard output from CLI\n            stderr: Standard error from CLI\n            \n        Returns:\n            Cleaned response text\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    def categorize_error(\n        self,\n        returncode: int,\n        stdout: str,\n        stderr: str,\n    ) -\u003e tuple[AdvisorError, str]:\n        \"\"\"\n        Categorize CLI error based on output.\n        \n        Args:\n            returncode: Exit code from CLI\n            stdout: Standard output\n            stderr: Standard error\n            \n        Returns:\n            (error_category, human_readable_message)\n        \"\"\"\n        pass\n    \n    @abstractmethod\n    async def check_available(self) -\u003e AvailabilityResult:\n        \"\"\"\n        Check if CLI is installed and authenticated.\n        \n        Should perform minimal check (not a full API call).\n        \n        Returns:\n            AvailabilityResult with status\n        \"\"\"\n        pass\n    \n    async def run(\n        self,\n        prompt: str,\n        timeout: float = 600.0,\n        cwd: Path | None = None,\n    ) -\u003e AdvisorResult:\n        \"\"\"\n        Run CLI with prompt and return full result.\n        \n        Handles subprocess execution, timeout, and error categorization.\n        \n        Args:\n            prompt: The prompt to send\n            timeout: Maximum execution time in seconds\n            cwd: Working directory (default: current)\n            \n        Returns:\n            AdvisorResult with response or error info\n        \"\"\"\n        cmd = self.build_command(prompt)\n        start_time = time.monotonic()\n        \n        try:\n            process = await asyncio.create_subprocess_exec(\n                *cmd,\n                cwd=str(cwd) if cwd else None,\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE,\n            )\n            \n            stdout_bytes, stderr_bytes = await asyncio.wait_for(\n                process.communicate(),\n                timeout=timeout,\n            )\n            \n            duration_ms = int((time.monotonic() - start_time) * 1000)\n            stdout = stdout_bytes.decode('utf-8', errors='replace')\n            stderr = stderr_bytes.decode('utf-8', errors='replace')\n            \n            if process.returncode == 0:\n                content = self.parse_output(stdout, stderr)\n                return AdvisorResult.success_result(\n                    provider=self.name,\n                    content=content,\n                    duration_ms=duration_ms,\n                )\n            else:\n                error, message = self.categorize_error(\n                    process.returncode, stdout, stderr\n                )\n                return AdvisorResult.failure_result(\n                    provider=self.name,\n                    error=error,\n                    error_message=message,\n                    duration_ms=duration_ms,\n                )\n                \n        except asyncio.TimeoutError:\n            duration_ms = int((time.monotonic() - start_time) * 1000)\n            return AdvisorResult.failure_result(\n                provider=self.name,\n                error=AdvisorError.TIMEOUT,\n                error_message=f'Exceeded {timeout}s timeout',\n                duration_ms=duration_ms,\n            )\n        except FileNotFoundError:\n            duration_ms = int((time.monotonic() - start_time) * 1000)\n            return AdvisorResult.failure_result(\n                provider=self.name,\n                error=AdvisorError.CLI_NOT_FOUND,\n                error_message=f'{self.name} CLI not found in PATH',\n                duration_ms=duration_ms,\n            )\n    \n    async def stream(\n        self,\n        prompt: str,\n        timeout: float = 600.0,\n        cwd: Path | None = None,\n    ) -\u003e AsyncIterator[StreamEvent]:\n        \"\"\"\n        Stream CLI output for real-time display.\n        \n        Yields StreamEvent objects as output arrives.\n        Final event will be type=DONE or type=ERROR.\n        \n        Args:\n            prompt: The prompt to send\n            timeout: Maximum execution time\n            cwd: Working directory\n            \n        Yields:\n            StreamEvent objects\n        \"\"\"\n        cmd = self.build_command(prompt)\n        start_time = time.monotonic()\n        \n        def elapsed() -\u003e float:\n            return time.monotonic() - start_time\n        \n        try:\n            process = await asyncio.create_subprocess_exec(\n                *cmd,\n                cwd=str(cwd) if cwd else None,\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE,\n            )\n            \n            # Read stdout line by line\n            async def read_stream():\n                while True:\n                    line = await asyncio.wait_for(\n                        process.stdout.readline(),\n                        timeout=timeout - elapsed(),\n                    )\n                    if not line:\n                        break\n                    yield StreamEvent.text(\n                        line.decode('utf-8', errors='replace'),\n                        elapsed(),\n                    )\n            \n            async for event in read_stream():\n                yield event\n            \n            await process.wait()\n            \n            if process.returncode == 0:\n                yield StreamEvent.done(elapsed())\n            else:\n                stderr = await process.stderr.read()\n                error, message = self.categorize_error(\n                    process.returncode, '', stderr.decode()\n                )\n                yield StreamEvent.error(message, elapsed())\n                \n        except asyncio.TimeoutError:\n            yield StreamEvent.error(\n                f'Exceeded {timeout}s timeout',\n                elapsed(),\n            )\n        except FileNotFoundError:\n            yield StreamEvent.error(\n                f'{self.name} CLI not found',\n                elapsed(),\n            )\n```\n\n## Acceptance Criteria\n- [ ] ABC with all abstract methods defined\n- [ ] `run()` method handles success, failure, timeout\n- [ ] `stream()` method yields events in real-time\n- [ ] FileNotFoundError caught and categorized\n- [ ] Timeout handled gracefully\n- [ ] All methods have comprehensive docstrings\n- [ ] Type hints complete\n\n## Testing Strategy\n```python\n# Test with mock adapter\nclass MockAdapter(ProviderAdapter):\n    name = 'mock'\n    \n    def build_command(self, prompt):\n        return ['echo', prompt]\n    \n    def parse_output(self, stdout, stderr):\n        return stdout.strip()\n    \n    def categorize_error(self, returncode, stdout, stderr):\n        return AdvisorError.UNKNOWN, 'Mock error'\n    \n    async def check_available(self):\n        return AvailabilityResult('mock', True)\n\nasync def test_mock_adapter_run():\n    adapter = MockAdapter()\n    result = await adapter.run('hello')\n    assert result.success\n    assert result.content == 'hello'\n```","status":"open","priority":1,"issue_type":"task","owner":"mjfork@users.noreply.github.com","created_at":"2026-01-15T23:11:59.615436-06:00","created_by":"Michael Fork","updated_at":"2026-01-15T23:11:59.615436-06:00","labels":["abstract","adapter","foundation"],"dependencies":[{"issue_id":"meld-eq0.3.2","depends_on_id":"meld-eq0.3","type":"parent-child","created_at":"2026-01-15T23:11:59.616279-06:00","created_by":"Michael Fork"}]}
